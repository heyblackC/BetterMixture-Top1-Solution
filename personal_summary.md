### 参赛背景和动机
大模型数据混合挑战赛BetterMixture在2024年2月初开始，同年4月初结束，该赛事由modelscope团队举办，被发布在阿里云天池算法大赛赛道上。当时我们团队实施的项目中正好涉及大模型数据的预处理，包括数据去重、清洗、质量筛选等步骤，我认为BetterMixture挑战赛是一个和我从事的方向相当契合的学习和实践机会，于是以个人名义单人队伍报名了该比赛，队伍名称是“柠子小分队”。
### 赛事简介
BetterMixture竞赛分为初赛、复赛和获奖后技术分享。该竞赛的基本要求是在给定的计算量约束下（仅10M tokens训练量），通过数据去重、清洗和数据配比，来实现对大模型的高效率、高效果微调。具体来说，BetterMixture指定以Baichuan2-7B模型作为基座，限定只能用Lora低秩微调（在训练中仅0.05%的参数会被调整），并给定了SFT训练的原始数据集和评测数据集，评测数据集主要评估的是模型的**自然语言推理能力、事实陈述能力（是否有幻觉）、数学能力、中英文常识选择题能力和总结摘要能力**。此外，初赛时使用的评测数据集是公开数据集，复赛时会额外加入举办方收集的私有数据集。实践下来，基于Baichuan2-7B模型进行LoRA训练，训练10M tokens（共4w-5w条数据），且epoch数固定为3轮，单节点双卡大约只需要6小时来训练。
### 打比赛的过程和个人感悟
比赛从今年2月开始，到4月结束，横跨一个农历新年，因此BetterMixture竞赛的工作有很大一部分是我在过年的时候抽空完成的。在比赛最初的阶段，我阅读了许多大模型数据工程的相关论文，认识到一份SFT数据集的质量可以由数据质量（data quality）、数据复杂度（data complexity）和数据多样性（data diversity）来衡量。当下业界比较公认的大模型数据处理步骤为数据去重、规则过滤、模型过滤、数据配比。我在这些前人工作的基础上结合BetterMixture竞赛的特点设计出了一套数据处理方案，流程为：原始数据打标—>规则过滤—>模型过滤—>三种粒度去重—>提高数学数据比重（竞赛方案细节放到了总结最后面），比赛实践也证明了我设计的这套方案确实能有效提升模型的效果。
打比赛一般都是先跑官方提供的Baseline基线模型，跑完Baseline模型后，我初步利用开源的质量过滤模型对数据做了筛选，筛选了数据后我的排名有所上升，但是并不高，只有十几名左右。这个时候我发现排名靠前的队伍其实只有**“数学能力”（GSM-8K）**指标比我的模型效果要好，其他指标都差不多。我意识到只要我把模型的数学能力提升上去，我就能提高排名。
#### 突破口：提高模型的数学能力
数学评测数据集GSM-8K由openAI开源，其中一个样例如下所示：Jenna and her mother picked some apples from their apple farm. Jenna picked half as many apples as her mom. If her mom got 20 apples, how many apples did they both pick?
Jenna picked 20/2 = <<20/2=10>>10 apples\nThey both picked 10+20 = <<10+20=30>>30 apples\n#### 
从人类的角度来看，我发现GSM8K数学评测想要获得高分，有三个点需要注意：

- 题意理解。数学题往往有背景设置，有出场人物A、B，最后出题角度甚至还有点绕弯（例如，小A买了10个苹果，小B买了小A的2倍，问一共买了多少苹果？），大模型需要准确理解题意，想出正确的解题思路。
- 加减乘除法四则运算能力。大模型的加减乘除一定要算对，否则题意理解到位了也没用。一道题可能涉及三、四步的运算，这就要求模型在长链路推理下保证计算的正确性。
- 格式输出能力（指令遵循能力）。最终运算结果必须跟在####四个#号后面，如果模型没有输出####，那么算对了也没用。

进一步地，我在实践中观察到一个现象，1e-4的lora微调在学习GSM8K类似的数学知识时非常差，即使epoch设置为3，学完后计算仍旧大概率出现错误，1e-3的学习率才能够有效学习数学能力。然而，总结摘要能力、事实陈述能力都只需要在1e-4的学习率下学习即可。
因此针对数学能力提高的问题，考虑到7B小模型数学逻辑推理能力的欠缺，我在实验中采用了提高学习率+清理高等数学，只保留小学数学，以集中、高强度的方式把基础数学知识灌进7b小模型脑子里。后续我还针对数学数据计算了数学相关度得分，以及对数学数据中的数学表达式计算做了检验。
数学评测指标提升上去后，我的初赛名次基本上就来到了排行榜前列，但离第一名还有距离，这个时候我观察到数据集中有很多脏数据和代码生成数据（代码能力在本次竞赛中并不需要），因此我开始对数据集做更系统的分析。
#### 效果进一步提升：数据分析和数据过滤
我分析了训练SFT数据集的组成来源分布、输出长度分布、输入prompt长度分布、输出输入长度比分布等，并且筛选出部分数据进行人工检查。检查过程中我发现原始数据中有很多“脏”数据是可以直接删除的，例如一些垃圾对话、代码生成数据、带有html块、代码块、markdown格式输出数据等。此外由于这份数据集中很多数据来源于社区分享出来的chatGPT对话，因此数据中可能还会带有超链接、图片上传链接，以及不少URL_*模式的引用链接数据，这类数据输入到纯文本大模型中只会引发幻觉，因此必须过滤掉。还有就是不少GPT生成数据中其实本身就包含事实性错误、数学计算错误等，语言类的错误比较难以判别，但是数学计算错误是能够被识别的，因此数学计算错误数据也要被过滤。
因此，我设计了一套数据过滤方法去过滤以下数据：

- sharegpt多轮对话融合混淆
- alpaca尖括号内容<noinput>，nooutput输出
- 模型输出多段内容编号错误
- 代码输出和html格式输出
- 过滤emogji数据
- 过滤的超链接数据、URL_*模式的引用链接数据
- html block、代码、markdown格式输出数据
- chatGPT自我意识数据
- 使用正则表达式和python计算器捕获和验证数学等式，将错误的数学计算结果数据删去

到了初赛后期，我的数据处理流程和系统已经基本完善，名次也上升到了第一名，其中模型的数学能力和总结摘要能力比较突出。到后面我就把精力放在尝试不同的超参数组合以及调整数据处理的流程上面。因为在过年期间也常常拿着电脑分析数据、看badcase以及写代码，身边的亲人好友都比较关心我能不能保持第一名，可能是其他参赛选手在过年期间都比较松懈，我的初赛第一名一直维持到了初赛结束。
复赛的时候已经返回日常工作了，我没有再投入太多的精力，复赛的方案和初赛一模一样，复赛的时候其他选手后劲比较强，我复赛取得的是第三名。但其实前三名的复赛分数相差无几，非常非常接近。最终成绩的计算方法为：**最终成绩 =** **初赛成绩 * 0.5 + 复赛成绩 * 0.5。**在看到对手在复赛超越我时，其实内心也比较忐忑，算了好几遍最终成绩，最终确信自己初赛成绩比较高，应该能保持第一名到最后。
最终我的方案取得了初赛第一，复赛第三，总榜第一，拿到了最后的冠军，以及1万元奖金（税后其实只有8000元）。
### 赛事结束后的交流和分享
竞赛介绍页面：[https://tianchi.aliyun.com/competition/entrance/532174](https://tianchi.aliyun.com/competition/entrance/532174)
BetterMixture获奖名单页面：[https://tianchi.aliyun.com/forum/post/677218](https://tianchi.aliyun.com/forum/post/677218)
BetterMixture第一名方案分享帖子-by柠子小分队：[https://tianchi.aliyun.com/forum/post/680153](https://tianchi.aliyun.com/forum/post/680153)
整体方案细节技术分享帖子：![image.png](https://intranetproxy.alipay.com/skylark/lark/0/2024/png/107356657/1718166014337-836f05a0-7fdb-489b-8f97-1d71fe1d7f72.png#clientId=u8a43470a-3b7c-4&from=paste&height=94&id=u67de8719&originHeight=188&originWidth=2418&originalType=binary&ratio=2&rotation=0&showTitle=false&size=190877&status=done&style=none&taskId=udf2d2b23-fe45-4216-86e1-7a88e4a332a&title=&width=1209)
[https://github.com/heyblackC/BetterMixture-Top1-Solution?spm=a2c22.21852664.0.0.3b665a84LNlz8r](https://github.com/heyblackC/BetterMixture-Top1-Solution?spm=a2c22.21852664.0.0.3b665a84LNlz8r)
最后，我和总榜第二名的队伍交流了各自的方案，会发现其实大家有共同的认知，也有完全不一样的选择，例如，我们都认为数学数据很重要，都大量地加入了数学数据。但是第二名的队伍认为有些数据来源本身就是低质量的，可以全部抛弃，我则没有采用这种做法。还有就是第二名队伍用的学习率也和我不一样，我是1e-3，他们是1e-4，这些差异点很值得后续进一步研究和探讨。
